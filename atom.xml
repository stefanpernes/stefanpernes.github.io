<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

	<title><![CDATA[Notizen]]></title>
	<link href="http://stefanpernes.github.io/atom.xml" rel="self"/>
	<link href="http://stefanpernes.github.io/"/>
	<updated>2015-04-16T22:17:22+02:00</updated>
	<id>http://stefanpernes.github.io/</id>
	<author>
		<name><![CDATA[Stefan Pernes]]></name>
		
	</author>
	<generator uri="http://octopress.org/">Octopress</generator>

	
	<entry>
		
			<title type="html"><![CDATA[Clustering in LSA space]]></title>
		
		<link href="http://stefanpernes.github.io/blog/2015/03/27/clustering-in-lsa-space/"/>
		<updated>2015-03-27T15:50:46+01:00</updated>
		<id>http://stefanpernes.github.io/blog/2015/03/27/clustering-in-lsa-space</id>
		<content type="html">
			<![CDATA[
				
					<p></p>
				
			]]>
			<![CDATA[<p>Actually, this is something I tried out over the christmas holidays and never quite found the time to get back to, but after I had the chance to meet <a href="https://www.cl.cam.ac.uk/~ah433/">Aur√©lie Herbelot</a> at the <a href="http://www.volkswagenstiftung.de/veranstaltungen/veranstaltungskalender/veranstdet/news/detail/artikel/herrenhaeuser-konferenz-big-data-in-a-transdisciplinary-perspective/marginal/4525.html">Herrenhausen conference on big data</a> this week and discuss her work on the <a href="https://www.cl.cam.ac.uk/~ah433/LLC.pdf">distributional semantics of poetry</a>, it all came back to me. In short - and please excuse any misrepresentation - Herbelot derives a measure of text coherence from the semantic spaces and uses it to display a variety of texts as a continuum ranging from &lsquo;random&rsquo; to &lsquo;poetic&rsquo; to &lsquo;factual&rsquo;. Now, what I just wanted to show here was something very similar that I ran into when using <a href="http://othes.univie.ac.at/27166/">my master&rsquo;s thesis</a> to build an LSA model (using 500 word chunks as documents) and plot it. The clustering algorithm that ran on top is almost unnecessary as the data points themselves display something very clearly: The chunks of highly self-referential and redundant academic text form dense assemblages, whereas the transcriptions of children&rsquo;s discussions distribute themselves broadly. What also becomes visible are two threads, which correspond to the two different focus groups I conducted.</p>

<p><a href="http://stefanpernes.github.io/images/posts/diplomarbeit.png" class="fresco"><img src=/images/posts/diplomarbeit.png></a></p>

<p>Leaving out the appendix that holds the complete transcriptions reveals shorter passages cited in the text:</p>

<p><a href="http://stefanpernes.github.io/images/posts/diplomarbeit_ohneanhang.png" class="fresco"><img src=/images/posts/diplomarbeit_ohneanhang.png></a></p>

<p>Made using python, respectively gensim and sklearn. Code will follow at some point, all of this needs some more work.</p>
]]>
		</content>
	</entry>
	
	<entry>
		
			<title type="html"><![CDATA[Musil's man without qualities]]></title>
		
		<link href="http://stefanpernes.github.io/blog/2014/09/18/musils-man-without-qualities/"/>
		<updated>2014-09-18T12:41:37+02:00</updated>
		<id>http://stefanpernes.github.io/blog/2014/09/18/musils-man-without-qualities</id>
		<content type="html">
			<![CDATA[
				
					<p></p>
				
			]]>
			<![CDATA[<p>At our DARIAH-DE cluster unconference last week we had time to develop a simple new workflow using DKPro, Jython and Gephi. We use the Apache UIMA based framework to do the heavy lifting, in this case everything up to and including named entity recognition (NER). We invoke the pipeline and process its output via a Python script.</p>

<p>Here the basic idea is to find a window within which to count occuring named entities as connected. Any two entities within that window (and if there are more, all combinations count) are taken as nodes, put together, and written as edges into a .csv file. That .csv file can be imported into Gephi in order to produce network graphs like the ones shown below [from the <a href="http://gutenberg.spiegel.de/buch/der-mann-ohne-eigenschaften-erstes-buch-7588/1">1st book</a> of Musil&rsquo;s man without qualities]:</p>

<p><a href="http://stefanpernes.github.io/images/posts/musil_paragraphs_z.png" class="fresco"><img src=/images/posts/musil_paragraphs_z.png></a></p>

<p>The paragraph segmentation above (note to self: use the DKPro built-in paragraph splitter) yields quite a complete picture of mentions, whereas the co-occurence within sentences should be indicative of a more direct connection between mentioned entities:</p>

<p><a href="http://stefanpernes.github.io/images/posts/musil_sentences_z.png" class="fresco"><img src=/images/posts/musil_sentences_z.png></a></p>

<p>As the StanfordNamedEntityRecognizer must be instructed to look for specific kinds of entities, I tried them all and apart from the &lsquo;person&rsquo; attribute, &lsquo;location&rsquo; led to the extraction of a meaningful network from that novel:</p>

<p><a href="http://stefanpernes.github.io/images/posts/musil_paragraphs_location.png" class="fresco"><img src=/images/posts/musil_paragraphs_location.png></a></p>

<p>As can be observed looking at close-ups of the network graph, NER needs to be improved - in at least two ways: to tune it for German as well as for literary texts. Another thing that can be experimented with is what segmentation(s) to use. A more theoretical approach, for example based on concepts of scene structure, might prove fruitful here - but also a little harder to implement.</p>

<p>[This is still work in progress, but some of our other recipes are online already. You can find them <a href="https://code.google.com/p/dkpro-tutorials/wiki/Jython_Tutorial">here</a>.]</p>
]]>
		</content>
	</entry>
	
</feed>
